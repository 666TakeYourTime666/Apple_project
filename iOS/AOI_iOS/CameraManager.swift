//
//  CameraManager.swift
//  MultiCamiOS
//
//  Created by ZSS on 2025/8/7.
//

import AVFoundation
import Combine

final class CameraManager: NSObject, ObservableObject {

    static let shared = CameraManager()

    // MARK: - Core
    private let session = AVCaptureSession()
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")
    private let photoOutput = AVCapturePhotoOutput()

    private var currentInput: AVCaptureDeviceInput?
    private var completionHandler: ((Data?) -> Void)?
    private var isCapturing = false

    // MARK: - State
    @Published private(set) var isConfigured = false

    enum LensMode {
        case wide       // 1x
        case ultraWide  // 0.5x
    }

    @Published private(set) var currentLens: LensMode = .wide

    // MARK: - Init
    override init() {
        super.init()
        configureSession()
    }

    // MARK: - Public
    func previewSession() -> AVCaptureSession {
        session
    }

    func switchLens(_ lens: LensMode) {
        sessionQueue.async {
            self.applyLens(lens)
        }
    }

    // MARK: - Session Setup
    private func configureSession() {
        sessionQueue.async {
            guard !self.isConfigured else { return }

            self.session.beginConfiguration()
            self.session.sessionPreset = .photo

            // 1ï¸âƒ£ å…ˆåŠ  inputï¼ˆä¸è®¾ç½® maxPhotoDimensionsï¼‰
            self.applyLens(.wide, configureOutput: false)

            // 2ï¸âƒ£ å†åŠ  output
            if self.session.canAddOutput(self.photoOutput) {
                self.session.addOutput(self.photoOutput)
                self.photoOutput.isHighResolutionCaptureEnabled = true
            }

            self.session.commitConfiguration()

            // 3ï¸âƒ£ commit åé…ç½®å°ºå¯¸ï¼ˆå®‰å…¨ï¼‰
            self.configurePhotoOutput(for: .wide)

            self.session.startRunning()

            DispatchQueue.main.async {
                self.isConfigured = true
            }

            print("âœ… Camera Session é…ç½®å®Œæˆ")
        }
    }

    // MARK: - Lens Apply
    private func applyLens(_ lens: LensMode, configureOutput: Bool = true) {
        let deviceType: AVCaptureDevice.DeviceType =
            (lens == .wide) ? .builtInWideAngleCamera : .builtInUltraWideCamera

        guard let device = AVCaptureDevice.default(deviceType,
                                                   for: .video,
                                                   position: .back) else {
            print("âŒ æœªæ‰¾åˆ°æ‘„åƒå¤´: \(deviceType)")
            return
        }

        do {
            let newInput = try AVCaptureDeviceInput(device: device)

            session.beginConfiguration()

            if let currentInput {
                session.removeInput(currentInput)
            }

            if session.canAddInput(newInput) {
                session.addInput(newInput)
                currentInput = newInput
            }

            session.commitConfiguration()

            // âš ï¸ å¿…é¡»åœ¨ commit ä¹‹å
            if configureOutput {
                configurePhotoOutput(for: lens)
            }

            DispatchQueue.main.async {
                self.currentLens = lens
            }

            print("ğŸ”„ å·²åˆ‡æ¢é•œå¤´: \(lens)")
        } catch {
            session.commitConfiguration()
            print("âŒ åˆ‡æ¢é•œå¤´å¤±è´¥: \(error)")
        }
    }

    // MARK: - Photo Output Configuration
    private func configurePhotoOutput(for lens: LensMode) {

        guard photoOutput.connections.contains(where: { $0.isEnabled }) else {
            print("âš ï¸ PhotoOutput å°šæœªè¿æ¥ï¼Œè·³è¿‡å°ºå¯¸é…ç½®")
            return
        }

        guard let input = currentInput,
              input.device.activeFormat != nil else {
            print("âš ï¸ activeFormat ä¸º nilï¼Œè·³è¿‡ maxPhotoDimensions")
            return
        }

        photoOutput.isHighResolutionCaptureEnabled = true

        if #available(iOS 17.0, *) {
            switch lens {
            case .wide:
                photoOutput.maxPhotoDimensions =
                    CMVideoDimensions(width: 8064, height: 6048)
                print("ğŸ“ ä½¿ç”¨ 48MP è¾“å‡º")

            case .ultraWide:
                photoOutput.maxPhotoDimensions =
                    CMVideoDimensions(width: 4032, height: 3024)
                print("ğŸ“ ä½¿ç”¨ 12MP è¾“å‡º")
            }
        }
    }
}

// MARK: - Photo Capture
extension CameraManager: AVCapturePhotoCaptureDelegate {

    func capture(completion: @escaping (Data?) -> Void) {
        guard !isCapturing else {
            print("âš ï¸ æ­£åœ¨æ‹ç…§ï¼Œå¿½ç•¥é‡å¤è¯·æ±‚")
            return
        }

        isCapturing = true
        completionHandler = { [weak self] data in
            completion(data)
            self?.isCapturing = false
        }

        sessionQueue.async {
            guard self.isConfigured else {
                DispatchQueue.main.async {
                    self.isCapturing = false
                    completion(nil)
                }
                return
            }

            let settings = AVCapturePhotoSettings()
            settings.photoQualityPrioritization = .quality
            settings.isHighResolutionPhotoEnabled = true

            if self.photoOutput.isStillImageStabilizationSupported {
                settings.isAutoStillImageStabilizationEnabled = false
            }

            print("ğŸ“¸ æ‹ç…§è§¦å‘ï¼ˆ\(self.currentLens)ï¼‰")
            self.photoOutput.capturePhoto(with: settings, delegate: self)
        }
    }

    // MARK: - Delegate
    func photoOutput(_ output: AVCapturePhotoOutput,
                     didFinishProcessingPhoto photo: AVCapturePhoto,
                     error: Error?) {

        if let error {
            print("âŒ æ‹ç…§å¤±è´¥: \(error)")
            DispatchQueue.main.async {
                self.completionHandler?(nil)
            }
            return
        }

        guard let data = photo.fileDataRepresentation() else {
            DispatchQueue.main.async {
                self.completionHandler?(nil)
            }
            return
        }

        print("âœ… æ‹ç…§å®Œæˆï¼Œsize = \(data.count)")
        DispatchQueue.main.async {
            self.completionHandler?(data)
        }
    }

    func photoOutput(_ output: AVCapturePhotoOutput,
                     didFinishCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings,
                     error: Error?) {

        if let error {
            print("âŒ æ‹ç…§æµç¨‹å¼‚å¸¸: \(error)")
        } else {
            print("ğŸ“¸ æ‹ç…§æµç¨‹ç»“æŸ")
        }
    }
}

